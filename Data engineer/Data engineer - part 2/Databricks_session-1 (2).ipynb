{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bbb4149-04a8-46c4-b360-f3fdd155b1f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Region: string (nullable = true)\n |-- Country: string (nullable = true)\n |-- ItemType: string (nullable = true)\n |-- SalesChannel: string (nullable = true)\n |-- OrderPriority: string (nullable = true)\n |-- OrderID: string (nullable = true)\n |-- UnitsSold: string (nullable = true)\n |-- UnitPrice: string (nullable = true)\n |-- UnitCost: string (nullable = true)\n |-- TotalRevenue: string (nullable = true)\n |-- TotalCost: string (nullable = true)\n |-- TotalProfit: string (nullable = true)\n\nroot\n |-- Region: string (nullable = true)\n |-- Country: string (nullable = true)\n |-- ItemType: string (nullable = true)\n |-- SalesChannel: string (nullable = true)\n |-- OrderPriority: string (nullable = true)\n |-- OrderID: integer (nullable = true)\n |-- UnitsSold: integer (nullable = true)\n |-- UnitPrice: double (nullable = true)\n |-- UnitCost: double (nullable = true)\n |-- TotalRevenue: double (nullable = true)\n |-- TotalCost: double (nullable = true)\n |-- TotalProfit: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.load(\"/FileStore/tables/Order.csv\",format='csv')    # reading file\n",
    "#display(df)  (display is a databricks specific function)\n",
    "# df.show() #show\n",
    "df = spark.read.load(\"/FileStore/tables/Order.csv\",format='csv',header=True) #treates first row as a header\n",
    "# display(df)\n",
    "df.printSchema()\n",
    "df1 = spark.read.load(\"/FileStore/tables/Order.csv\",header=True,format='csv',inferschema=True) #adjust the schema by reading data in file\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8033d1eb-2190-4b91-a4fd-4ba788dfd1de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+------------+-------------+\n|              region|   country|  ItemType|SalesChannel|OrderPriority|\n+--------------------+----------+----------+------------+-------------+\n|Middle East and N...|     Libya| Cosmetics|     Offline|            M|\n|       North America|    Canada|Vegetables|      Online|            M|\n|Middle East and N...|     Libya| Baby Food|     Offline|            C|\n|                Asia|     Japan|    Cereal|     Offline|            C|\n|  Sub-Saharan Africa|      Chad|    Fruits|     Offline|            H|\n|              Europe|   Armenia|    Cereal|      Online|            H|\n|  Sub-Saharan Africa|   Eritrea|    Cereal|      Online|            H|\n|              Europe|Montenegro|   Clothes|     Offline|            M|\n|Central America a...|   Jamaica|Vegetables|      Online|            H|\n|Australia and Oce...|      Fiji|Vegetables|     Offline|            H|\n+--------------------+----------+----------+------------+-------------+\nonly showing top 10 rows\n\nroot\n |-- region: string (nullable = true)\n |-- country: string (nullable = true)\n |-- ItemType: string (nullable = true)\n |-- SalesChannel: string (nullable = true)\n |-- OrderPriority: string (nullable = true)\n\n+--------------------+----------+------------+---------+---------+---------+--------+------------+----------+-----------+\n|              Region|   Country|SalesChannel|  OrderID|UnitsSold|UnitPrice|UnitCost|TotalRevenue| TotalCost|TotalProfit|\n+--------------------+----------+------------+---------+---------+---------+--------+------------+----------+-----------+\n|Middle East and N...|     Libya|     Offline|686800706|     8446|    437.2|  263.33|   3692591.2|2224085.18| 1468506.02|\n|       North America|    Canada|      Online|185941302|     3018|   154.06|   90.93|   464953.08| 274426.74|  190526.34|\n|Middle East and N...|     Libya|     Offline|246222341|     1517|   255.28|  159.42|   387259.76| 241840.14|  145419.62|\n|                Asia|     Japan|     Offline|161442649|     3322|    205.7|  117.11|    683335.4| 389039.42|  294295.98|\n|  Sub-Saharan Africa|      Chad|     Offline|645713555|     9845|     9.33|    6.92|    91853.85|   68127.4|   23726.45|\n|              Europe|   Armenia|      Online|683458888|     9528|    205.7|  117.11|   1959909.6|1115824.08|  844085.52|\n|  Sub-Saharan Africa|   Eritrea|      Online|679414975|     2844|    205.7|  117.11|    585010.8| 333060.84|  251949.96|\n|              Europe|Montenegro|     Offline|208630645|     7299|   109.28|   35.84|   797634.72| 261596.16|  536038.56|\n|Central America a...|   Jamaica|      Online|266467225|     2428|   154.06|   90.93|   374057.68| 220778.04|  153279.64|\n|Australia and Oce...|      Fiji|     Offline|118598544|     4800|   154.06|   90.93|    739488.0|  436464.0|   303024.0|\n+--------------------+----------+------------+---------+---------+---------+--------+------------+----------+-----------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "#to define own schema 2 approches using traditional pyspark or using sql\n",
    "#using traditional method\n",
    "from pyspark.sql.types import *\n",
    "orderschema = StructType([StructField(\"Region\", StringType(), True),\n",
    "                         StructField(\"Country\", StringType(), True)])\n",
    "df = spark.read.load(\"/FileStore/tables/Order.csv\",header=True,format='csv', schema=orderschema) #schema will take our own schema\n",
    "# display(df)\n",
    "#sql method (most using and easy way)\n",
    "orderschema_sql = \"region string, country String, ItemType String, SalesChannel String, OrderPriority String\"\n",
    "df_main = spark.read.load(\"/FileStore/tables/Order.csv\",header=True,format='csv', schema=orderschema_sql) #schema will take our own schema\n",
    "df_main.show(10)\n",
    "df_main.printSchema()\n",
    "df2= df1.drop(\"OrderPriority\",\"ItemType\")  # drop helps us to remove columns from our data frame\n",
    "df2.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ec9924d-94dc-46cb-91f5-0adda0b659ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>employee_id</th><th>employee_salary</th></tr></thead><tbody><tr><td>Pavan</td><td>1</td><td>50000</td></tr><tr><td>Sai</td><td>2</td><td>75000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Pavan",
         1,
         50000
        ],
        [
         "Sai",
         2,
         75000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "employee_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "employee_salary",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>full_name</th><th>employee_id</th><th>employee_salary</th></tr></thead><tbody><tr><td>Pavan</td><td>1</td><td>50000</td></tr><tr><td>Sai</td><td>2</td><td>75000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Pavan",
         1,
         50000
        ],
        [
         "Sai",
         2,
         75000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "full_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "employee_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "employee_salary",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#creating data frame manually\n",
    "# we need columns(schema) and rows for creating data frame\n",
    "# from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "row1 = Row(\"Pavan\", 1, 50000)\n",
    "row2 = Row(\"Sai\", 2, 75000)\n",
    "employee_schema = (\"name String, employee_id Integer, employee_salary Integer\")\n",
    "df = spark.createDataFrame([row1, row2], schema=employee_schema)\n",
    "display(df)\n",
    "\n",
    "#for selecting particular columns 5 methods \n",
    "df1 = df.select(\"name\", \"employee_id\") #for selecting particular multiple columns (popularly used)\n",
    "df2 = df.select(col(\"name\")) #drawback -- col,column,expr only can select 1 argument\n",
    "df3 = df.select(column(\"name\"))\n",
    "df4 = df.select(expr(\"name\")) #popularly used\n",
    "df5 = df.select(df.name,df.employee_salary)\n",
    "df6 = df.selectExpr(\"name as full_name\", \"employee_id\", \"employee_salary\") #for column selection along with column name change\n",
    "display(df6)\n",
    "# display(df4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68cca78f-8b45-4096-adf5-1327582267a7",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n|              Region|   Country|\n+--------------------+----------+\n|                Asia|     Japan|\n|Middle East and N...|     Libya|\n|  Sub-Saharan Africa|   Eritrea|\n|  Sub-Saharan Africa|      Chad|\n|              Europe|Montenegro|\n|       North America|    Canada|\n|Australia and Oce...|      Fiji|\n|              Europe|    Greece|\n|Central America a...|   Jamaica|\n|              Europe|   Armenia|\n+--------------------+----------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# display(df_main)\n",
    "df1 = df_main.withColumn(\"Flag\", lit(123))  #literals are constant values \n",
    "df2 = df1.withColumn(\"Country_india\", expr(\"country == 'India'\"))  #for inserting new column\n",
    "# display(df2)\n",
    "df3 = df2.withColumnRenamed(\"Country\",\"ALL_Countries\") # for renaming existing column\n",
    "# display(df3)\n",
    "df4 = df2.selectExpr(\"Country as countries_all\", \"region\", \"SalesChannel\") #for column selection along with column name change\n",
    "# display(df4)\n",
    "df5 = df4.drop(\"region\")  #dropping particular columns\n",
    "############################################################################################\n",
    "\n",
    "df6 = df1.where(\"Region = 'Asia' \") #to filter records can use either where or Filter \n",
    "df7 = df1.select(\"Region\",\"Country\").distinct() #for unique records selection\n",
    "df7.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ccb1ce8-1ac7-4ac1-9bc8-9985e790145f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Region</th><th>Country</th><th>OrderId</th></tr></thead><tbody><tr><td>Middle East and North Africa</td><td>Libya</td><td>686800706</td></tr><tr><td>Middle East and North Africa</td><td>Libya</td><td>246222341</td></tr><tr><td>Middle East and North Africa</td><td>Libya</td><td>964214932</td></tr><tr><td>Middle East and North Africa</td><td>Libya</td><td>635122907</td></tr><tr><td>Middle East and North Africa</td><td>Libya</td><td>276225316</td></tr><tr><td>Middle East and North Africa</td><td>Libya</td><td>854095017</td></tr><tr><td>Asia</td><td>Japan</td><td>161442649</td></tr><tr><td>Asia</td><td>Japan</td><td>981086671</td></tr><tr><td>Asia</td><td>Japan</td><td>823699796</td></tr><tr><td>Asia</td><td>Japan</td><td>629925000</td></tr><tr><td>Asia</td><td>Japan</td><td>107172334</td></tr><tr><td>Asia</td><td>Japan</td><td>885129249</td></tr><tr><td>Asia</td><td>Japan</td><td>551725089</td></tr><tr><td>Asia</td><td>Japan</td><td>453569972</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Middle East and North Africa",
         "Libya",
         "686800706"
        ],
        [
         "Middle East and North Africa",
         "Libya",
         "246222341"
        ],
        [
         "Middle East and North Africa",
         "Libya",
         "964214932"
        ],
        [
         "Middle East and North Africa",
         "Libya",
         "635122907"
        ],
        [
         "Middle East and North Africa",
         "Libya",
         "276225316"
        ],
        [
         "Middle East and North Africa",
         "Libya",
         "854095017"
        ],
        [
         "Asia",
         "Japan",
         "161442649"
        ],
        [
         "Asia",
         "Japan",
         "981086671"
        ],
        [
         "Asia",
         "Japan",
         "823699796"
        ],
        [
         "Asia",
         "Japan",
         "629925000"
        ],
        [
         "Asia",
         "Japan",
         "107172334"
        ],
        [
         "Asia",
         "Japan",
         "885129249"
        ],
        [
         "Asia",
         "Japan",
         "551725089"
        ],
        [
         "Asia",
         "Japan",
         "453569972"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Region",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "OrderId",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n Region  | Middle East and North Africa \n Country | Libya                        \n OrderId | 686800706                    \n-RECORD 1-------------------------------\n Region  | Middle East and North Africa \n Country | Libya                        \n OrderId | 246222341                    \n-RECORD 2-------------------------------\n Region  | Middle East and North Africa \n Country | Libya                        \n OrderId | 964214932                    \n-RECORD 3-------------------------------\n Region  | Middle East and North Africa \n Country | Libya                        \n OrderId | 635122907                    \n-RECORD 4-------------------------------\n Region  | Middle East and North Africa \n Country | Libya                        \n OrderId | 276225316                    \n-RECORD 5-------------------------------\n Region  | Middle East and North Africa \n Country | Libya                        \n OrderId | 854095017                    \n-RECORD 6-------------------------------\n Region  | Asia                         \n Country | Japan                        \n OrderId | 161442649                    \n-RECORD 7-------------------------------\n Region  | Asia                         \n Country | Japan                        \n OrderId | 981086671                    \n-RECORD 8-------------------------------\n Region  | Asia                         \n Country | Japan                        \n OrderId | 823699796                    \n-RECORD 9-------------------------------\n Region  | Asia                         \n Country | Japan                        \n OrderId | 629925000                    \n-RECORD 10------------------------------\n Region  | Asia                         \n Country | Japan                        \n OrderId | 107172334                    \n-RECORD 11------------------------------\n Region  | Asia                         \n Country | Japan                        \n OrderId | 885129249                    \n-RECORD 12------------------------------\n Region  | Asia                         \n Country | Japan                        \n OrderId | 551725089                    \n-RECORD 13------------------------------\n Region  | Asia                         \n Country | Japan                        \n OrderId | 453569972                    \n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Region</th><th>Country</th><th>OrderId</th></tr></thead><tbody><tr><td>Asia</td><td>Japan</td><td>161442649</td></tr><tr><td>Asia</td><td>Japan</td><td>981086671</td></tr><tr><td>Asia</td><td>Japan</td><td>823699796</td></tr><tr><td>Asia</td><td>Japan</td><td>629925000</td></tr><tr><td>Asia</td><td>Japan</td><td>107172334</td></tr><tr><td>Asia</td><td>Japan</td><td>885129249</td></tr><tr><td>Asia</td><td>Japan</td><td>551725089</td></tr><tr><td>Asia</td><td>Japan</td><td>453569972</td></tr><tr><td>Middle East and North Africa</td><td>Libya</td><td>686800706</td></tr><tr><td>Middle East and North Africa</td><td>Libya</td><td>246222341</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Asia",
         "Japan",
         "161442649"
        ],
        [
         "Asia",
         "Japan",
         "981086671"
        ],
        [
         "Asia",
         "Japan",
         "823699796"
        ],
        [
         "Asia",
         "Japan",
         "629925000"
        ],
        [
         "Asia",
         "Japan",
         "107172334"
        ],
        [
         "Asia",
         "Japan",
         "885129249"
        ],
        [
         "Asia",
         "Japan",
         "551725089"
        ],
        [
         "Asia",
         "Japan",
         "453569972"
        ],
        [
         "Middle East and North Africa",
         "Libya",
         "686800706"
        ],
        [
         "Middle East and North Africa",
         "Libya",
         "246222341"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Region",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "OrderId",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------+-------------------+\n|summary|              Region|Country|            OrderId|\n+-------+--------------------+-------+-------------------+\n|  count|                  10|     10|                 10|\n|   mean|                null|   null|      5.526773807E8|\n| stddev|                null|   null|3.067292352880238E8|\n|    min|                Asia|  Japan|          107172334|\n|    max|Middle East and N...|  Libya|          981086671|\n+-------+--------------------+-------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "#union in spark\n",
    "df1 = spark.read.load(\"/FileStore/tables/Order.csv\",header=True,format='csv')\n",
    "df2 = df1.select(\"Region\",\"Country\",\"OrderId\")\n",
    "df3 = df2.filter(\"Country == 'Libya'\")\n",
    "df4 = df2.filter(\"Country == 'Japan'\")\n",
    "df4_union = df3.union(df4) #accepts only one argument merging of data of same column\n",
    "display(df4_union)\n",
    "df4_union.count()\n",
    "\n",
    "#orderby -- sorting\n",
    "df4_union.sort(col(\"Region\").desc()).show(20, truncate=False, vertical = True) #displays in vertical format(20 rows), truncation not allowed\n",
    "df5 = df4_union.sort(col(\"Region\").asc()) #sorting in ascending order\n",
    "df6 = df5.limit(10) #limiting the columns to 10\n",
    "display(df6)\n",
    "\n",
    "df6.collect() #not recommended because it collects all data from all machines and then prints the data\n",
    "df7 = df6.describe() #describes mean,count,median\n",
    "df7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6086380b-1289-4786-811c-72f2726d2c77",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n|upper(Region)|\n+-------------+\n|ASIA         |\n|ASIA         |\n+-------------+\nonly showing top 2 rows\n\n+-------------+\n|lower(Region)|\n+-------------+\n|         asia|\n|         asia|\n+-------------+\nonly showing top 2 rows\n\n+---------------+\n|initcap(Region)|\n+---------------+\n|           Asia|\n|           Asia|\n+---------------+\nonly showing top 2 rows\n\n+----------------------------+\n|trim(Region)                |\n+----------------------------+\n|Asia                        |\n|Asia                        |\n|Asia                        |\n|Asia                        |\n|Asia                        |\n|Asia                        |\n|Asia                        |\n|Asia                        |\n|Middle East and North Africa|\n|Middle East and North Africa|\n+----------------------------+\n\n+--------------------+\n|lpad(Region, 20, +) |\n+--------------------+\n|++++++++++++++++Asia|\n|++++++++++++++++Asia|\n|++++++++++++++++Asia|\n|++++++++++++++++Asia|\n|++++++++++++++++Asia|\n|++++++++++++++++Asia|\n|++++++++++++++++Asia|\n|++++++++++++++++Asia|\n|Middle East and Nort|\n|Middle East and Nort|\n+--------------------+\n\n+-----------------------+\n|concat(Region, Country)|\n+-----------------------+\n|              AsiaJapan|\n|              AsiaJapan|\n|              AsiaJapan|\n|              AsiaJapan|\n|              AsiaJapan|\n|              AsiaJapan|\n|              AsiaJapan|\n|              AsiaJapan|\n|   Middle East and N...|\n|   Middle East and N...|\n+-----------------------+\n\n+-----------------------------------+\n|concat_ws(--, Region, Country)     |\n+-----------------------------------+\n|Asia--Japan                        |\n|Asia--Japan                        |\n|Asia--Japan                        |\n|Asia--Japan                        |\n|Asia--Japan                        |\n|Asia--Japan                        |\n|Asia--Japan                        |\n|Asia--Japan                        |\n|Middle East and North Africa--Libya|\n|Middle East and North Africa--Libya|\n+-----------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "#string manipulation functions\n",
    "df7 = df6.select(upper(col(\"Region\"))).show(2, truncate=False) #all capital letters\n",
    "df8 = df6.select(lower(col(\"Region\"))).show(2) # all small letters\n",
    "df6.select(initcap(col(\"Region\"))).show(2) #first letter capital\n",
    "df6.select(trim(col(\"Region\"))).show(truncate=False) #removing spaces can use ltrim or rtrim for right or left space removal\n",
    "df6.select(lpad(col(\"Region\"),20,'+')).show(truncate=False) #can do for right padding also\n",
    "df6.select(concat(col(\"Region\"),col(\"Country\"))).show()  #concating within same data frame\n",
    "df6.select(concat_ws('--', col(\"Region\"),col(\"Country\"))).show(truncate=False) #concating with separator\n",
    "###################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0f2dc1c-2d18-4a67-9f05-654f7daa91a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-----------------------+\n|id |Date_current|Time_stamp             |\n+---+------------+-----------------------+\n|0  |2024-10-17  |2024-10-17 02:56:34.765|\n|1  |2024-10-17  |2024-10-17 02:56:34.765|\n|2  |2024-10-17  |2024-10-17 02:56:34.765|\n|3  |2024-10-17  |2024-10-17 02:56:34.765|\n|4  |2024-10-17  |2024-10-17 02:56:34.765|\n|5  |2024-10-17  |2024-10-17 02:56:34.765|\n|6  |2024-10-17  |2024-10-17 02:56:34.765|\n|7  |2024-10-17  |2024-10-17 02:56:34.765|\n|8  |2024-10-17  |2024-10-17 02:56:34.765|\n|9  |2024-10-17  |2024-10-17 02:56:34.765|\n+---+------------+-----------------------+\n\n+-------------------------+-------------------------+\n|date_add(Date_current, 5)|date_sub(Date_current, 5)|\n+-------------------------+-------------------------+\n|               2024-10-22|               2024-10-12|\n|               2024-10-22|               2024-10-12|\n|               2024-10-22|               2024-10-12|\n|               2024-10-22|               2024-10-12|\n|               2024-10-22|               2024-10-12|\n|               2024-10-22|               2024-10-12|\n|               2024-10-22|               2024-10-12|\n|               2024-10-22|               2024-10-12|\n|               2024-10-22|               2024-10-12|\n|               2024-10-22|               2024-10-12|\n+-------------------------+-------------------------+\n\n+---+----------+\n| id|      Date|\n+---+----------+\n|  0|2024-05-20|\n|  1|2024-05-20|\n+---+----------+\n\nroot\n |-- id: long (nullable = false)\n |-- Date: string (nullable = false)\n\nroot\n |-- new_date: date (nullable = true)\n\n+----------+\n|  new_date|\n+----------+\n|2024-05-25|\n|2024-05-25|\n+----------+\n\n+---------------+\n|month(new_date)|\n+---------------+\n|              5|\n|              5|\n+---------------+\n\n+--------------------+\n|dayofmonth(new_date)|\n+--------------------+\n|                  20|\n|                  20|\n+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "#date manipulation functions\n",
    "#range describes how many rows should be in new_data frame\n",
    "date_df = spark.range(10).withColumn(\"Date_current\",current_date()).withColumn(\"Time_stamp\",current_timestamp())\n",
    "date_df.show(truncate=False)\n",
    "date_df.select(date_add(\"Date_current\", 5), date_sub(\"Date_current\", 5)).show()  #date addition or subtraction by constant\n",
    "\n",
    "#converting to date data type\n",
    "const_df = spark.range(2).withColumn(\"Date\",lit(\"2024-05-20\"))\n",
    "const_df.show()\n",
    "const_df.printSchema()\n",
    "updated_df = const_df.select(to_date(col(\"Date\")).alias(\"new_date\")) #to_date converts string to date format,data should be date format \n",
    "updated_df.printSchema()\n",
    "updated_df.select(date_add(col(\"new_date\"),5).alias(\"new_date\")).show()\n",
    "updated_df.select(month(col(\"new_date\"))).show() #year,month,day can be extracted\n",
    "updated_df.select(dayofmonth(col(\"new_date\"))).show() \n",
    "#can also extract the minute,hour, second if it is a time stamp format"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Databricks_session-1",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
